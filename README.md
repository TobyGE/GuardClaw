# GuardClaw üõ°Ô∏èüêæ

Real-time security monitoring for AI agents ‚Äî powered by local LLMs. Every tool call gets risk-scored before it runs. 100% private, zero cloud.

![GuardClaw Dashboard](docs/screenshots/dashboard.jpg?v=1552)

## Requirements

- [LM Studio](https://lmstudio.ai) or [Ollama](https://ollama.ai) running locally
- [OpenClaw](https://github.com/openclaw/openclaw) or [nanobot](https://github.com/HKUDS/nanobot)

## Install

```bash
git clone https://github.com/TobyGE/GuardClaw.git
cd GuardClaw
npm install && npm install --prefix client && npm run build
npm link
```

## Start

```bash
guardclaw config detect-token --save   # auto-detect OpenClaw token
guardclaw start                        # opens browser automatically
```

Or skip the CLI: run `guardclaw start`, go to ‚öôÔ∏è Settings ‚Üí Gateway ‚Üí Auto-Detect.

## Advanced: Full Tool Event Monitoring (OpenClaw)

By default GuardClaw only receives text/chat events from OpenClaw. To see every tool call (read, write, exec, etc.) in real-time, run the included patch script:

```bash
bash scripts/patch-openclaw.sh
```

That's it. The script will patch OpenClaw, rebuild it, and restart the gateway automatically. It's safe to run multiple times (idempotent).

**What it does:** Adds one line to OpenClaw's WebSocket broadcast logic so that tool events are sent to all connected clients ‚Äî not just ones that started an agent run. GuardClaw is a passive observer and this is the only way it can receive tool events without interfering with normal operation.

## Advanced: Active Blocking

By default GuardClaw is **monitor-only** ‚Äî it shows risk scores but doesn't interfere with the agent.

Install the OpenClaw plugin to enable **pre-execution interception**:

| | Monitor only | With plugin |
|---|---|---|
| Risk scores + audit trail | ‚úÖ | ‚úÖ |
| Real-time tool call visibility | ‚úÖ | ‚úÖ |
| Block dangerous commands | ‚ùå | ‚úÖ |
| Approval prompts for high-risk (score ‚â• 8) | ‚ùå | ‚úÖ |

```bash
guardclaw plugin install
openclaw gateway restart
```

Once enabled, the üõ°Ô∏è button in the Dashboard toggles blocking on/off without a restart. Tools with a risk score ‚â• 8 are paused and require human approval ‚Äî respond with `/approve-last` or `/deny-last`. Below 8, tools run freely and risk scores are logged in the dashboard.

## Commands

```bash
guardclaw start / stop
guardclaw config detect-token --save
guardclaw config set-token <token>
guardclaw plugin install / uninstall / status
guardclaw help
```

## Roadmap / TODO

### Security Coverage
- [x] **Chained tool analysis** ‚Äî detect dangerous sequences rather than isolated calls (e.g. `web_fetch` ‚Üí `exec`, `read(sensitive file)` ‚Üí `message`). Each session maintains a rolling tool history (inputs + outputs); when an exit-type tool fires, the full trace is sent to the LLM in one call for holistic judgment.
- [x] **`write`/`edit` path analysis** ‚Äî rule-based fast path for persistence/backdoor paths: `authorized_keys`, shell startup files (`.bashrc`/`.zshrc`/`.profile` etc), AWS credentials, cron, macOS LaunchAgents/Daemons, git hooks, system paths. Score 9, no LLM call needed.
- [x] **Tool result inspection** ‚Äî covered by chained tool analysis: tool outputs (including secrets/PII) are stored in session history via `after_tool_call`; when a `message` or `exec` fires, the LLM sees the full trace including prior outputs and judges whether data is being exfiltrated.
- [x] **`canvas eval` analysis** ‚Äî `canvas` is excluded from the safe-tools fast path. Non-eval actions (`present`, `hide`, `navigate`, `snapshot`) ‚Üí score 1 (rules). `eval` actions ‚Üí full LLM analysis; prompt includes JS-specific risks (cookie/localStorage access, external `fetch`, `require`/`child_process`).
- [x] **`nodes invoke` analysis** ‚Äî analyzed by LLM; scoring prompt includes nodes-specific guidance (screen recording / camera without consent ‚Üí 8-9). Rule-based would over-block legitimate uses (e.g. taking a photo on request).

### Visibility
- [ ] **Cross-session security tracking** ‚Äî `sessions_spawn` and `sessions_send` create multi-agent topologies that single-session chain analysis cannot see. A compromised agent can call `sessions_send` to inject instructions into a peer session (prompt injection lateral movement), or read sensitive data in session A and exfiltrate via session B. Planned fix: log injections at `sessions_send` time, tag agent-injected messages in the receiver's chain context (`[‚ö†Ô∏è INJECTED from agent:X]`), and show session spawn lineage as a tree in the dashboard. Cross-session history will be persisted to disk so GuardClaw restarts don't create blind spots.

### Robustness
- [ ] **Fail-closed on GuardClaw disconnect** ‚Äî if the GuardClaw process crashes or the plugin loses its connection, tools currently execute unblocked (fail-open). Fix: plugin heartbeat to GuardClaw; if unreachable ‚Üí block tool execution until connection is restored. GuardClaw will also record its own PID at startup and treat any `kill`/`pkill` targeting that PID as a score-9 rule-based block.
- [ ] **Prompt injection defense on LLM judge** ‚Äî the rule-based layer only fast-paths *safe* tools; dangerous and ambiguous commands all go through the LLM judge. A malicious webpage fetched by the agent (low score, allowed) can embed adversarial text in the tool result that ends up in `chain_history` and manipulates the judge on a subsequent dangerous call. Fix: (1) wrap `chain_history` in XML tags with a system-prompt instruction to treat all content inside as raw data; (2) extend rule-based coverage for high-confidence dangerous patterns that should never reach the LLM (`nc`/`ncat` + external IP, `curl ‚Ä¶ | bash`, `base64 -d | bash`).
- [ ] **Write-file content scanning** ‚Äî after a `write` tool call, scan the file with traditional tools before closing the event: images ‚Üí StegDetect / stegoveritas (LSB steganography); text/binary ‚Üí entropy analysis, `strings`, `binwalk`. Scan results are appended to the LLM judge prompt alongside chain context so the model can reason holistically. Catches base64/hex encoding in text files reliably; catches binary steganography when steganalysis tools are available.

### UX
- [ ] **Approve/deny buttons in GuardClaw dashboard** ‚Äî click instead of typing `/approve-last`.

## Links

- [OpenClaw](https://github.com/openclaw/openclaw) ¬∑ [nanobot](https://github.com/HKUDS/nanobot) ¬∑ [LM Studio](https://lmstudio.ai)
- [Troubleshooting](docs/LMSTUDIO-TROUBLESHOOTING.md)
