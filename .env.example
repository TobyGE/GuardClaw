# Backend configuration
BACKEND=auto                              # auto | openclaw | nanobot
PORT=3001

# OpenClaw / Clawdbot Gateway
OPENCLAW_URL=ws://127.0.0.1:18789
OPENCLAW_TOKEN=your_gateway_token_here

# Nanobot
NANOBOT_URL=ws://127.0.0.1:18790

# Safeguard / LLM Backend
SAFEGUARD_BACKEND=lmstudio                # lmstudio | ollama | anthropic | fallback
LMSTUDIO_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=auto                       # auto | specific model name
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3
ANTHROPIC_API_KEY=your_api_key_here

# Approval Handler (Intelligent Command Blocking)
GUARDCLAW_APPROVAL_MODE=auto              # auto | prompt | monitor-only
GUARDCLAW_AUTO_ALLOW_THRESHOLD=6          # Risk ≤ this: auto-allow (default: 6)
GUARDCLAW_ASK_THRESHOLD=8                 # Risk between allow and block: ask user (default: 8)
GUARDCLAW_AUTO_BLOCK_THRESHOLD=9          # Risk ≥ this: auto-block (default: 9)

# Mode descriptions:
#   auto          - Auto-allow safe commands, auto-block dangerous ones
#   prompt        - Prompt user for medium-risk commands (7-8)
#   monitor-only  - Don't intercept, just monitor and analyze
